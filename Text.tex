\documentclass[8pt]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsopn}
\usepackage{comment}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{bussproofs}
\usepackage[all, 2cell]{xy}
\usepackage[all]{xy}
\usepackage{rotating}
\usepackage{lscape}
\usepackage{minted}


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]

\theoremstyle{definition}
\newtheorem{claim}{Claim}[section]

\theoremstyle{definition}
\newtheorem{ex}{Example}[section] 

\theoremstyle{definition}
\newtheorem{cons}{Construction}[section] 

\theoremstyle{definition}
\newtheorem{rem}{Remark}[section] 


\theoremstyle{definition}
\newtheorem{prop}{Proposition}[section]

\theoremstyle{definition}
\newtheorem{lemma}{Lemma}[section]

\theoremstyle{definition}
\newtheorem{fact}{Fact}[section]

\theoremstyle{definition}
\newtheorem{remark}{Remark}[section]

\theoremstyle{definition}
\newtheorem{notation}{Notation}[section]

\theoremstyle{definition}
\newtheorem{example}{Example}[section]

\theoremstyle{definition}
\newtheorem{col}{Corollary}[section]

\theoremstyle{question}
\newtheorem{question}{Question}

\let\strokeL\L
\renewcommand\L{\mathbf{L}}

\title{Some Notes on Proof Theory and Elements of Ordinal Analysis}
\author{Daniel Rogozin}
\date{ }

\begin{document}

\maketitle

\section{Provable Recursion in ${\bf I}\Delta_0(\operatorname{exp})$}

${\bf I}\Delta_0(\operatorname{exp})$ is a theory in first-order logic in the language:
\begin{center}
  $\{ =, 0, S, P, +, \dot{-}, \cdot, exp_2 \}$
\end{center}
where $S$ and $P$ are successor and precessor functions respectively.
Further, we will denote $S(x)$ and $P(x)$ as $x + 1$ and $x \dot{-} 1$ respectively.
$2^x$ stands for $exp_2(x)$.

The non-logical axioms of ${\bf I}\Delta_0(\operatorname{exp})$ are the following list:

\vspace{\baselineskip}

\begin{minipage}{0.45\textwidth}
  \begin{itemize}
    \item $x + 1 \neq 0$
    \item $0 \dot{-} 1 = 0$
    \item $x + 0 = x$
    \item $x \dot{-} 0 = x$
    \item $x \cdot 0 = 0$
    \item $2^0 = 1$
  \end{itemize}
\end{minipage}%
\hfill
\begin{minipage}{0.45\textwidth}
  \begin{itemize}
    \item $x + 1 = y + 1 \to x = y$
    \item $(x + 1) \dot{-} 1 = x$
    \item $x + (y + 1) = (x + y) + 1$
    \item $x \dot{-} (y + 1) = x \dot{-} y \dot{-} 1$
    \item $x \cdot (y + 1) = x \cdot y + x$
    \item $2^{x + 1} = 2^x + 2^x$
  \end{itemize}
\end{minipage}

\vspace{\baselineskip}

along with the bounded induction scheme:
\begin{center}
  $B(0) \land \forall x (B (x) \to B(x + 1)) \to \forall x B(x)$
\end{center}
where $B$ is a \emph{$\Delta$-formula}, that is a formula one of the following forms (with bounded quantifiers only):
\begin{itemize}
  \item $B \eqcirc \forall x < t P(x) \equiv \forall x (x < t \to P(x))$ 
  \item $B \eqcirc \exists x < t P(x) \equiv \exists x (x < t \land P(x))$
\end{itemize}

A $\Sigma_1$-formula is a formula of the form:
\begin{center}
  $\exists \vec{x} B(\vec{x})$
\end{center}
where $B(\vec{x}) \in \Delta_0$.

\begin{lemma}
  ${\bf I}\Delta_0(\operatorname{exp})$ proves (the universal closures of):
  \begin{enumerate}
    \item $x = 0 \lor x = (x \dot{-} 1) + 1$
    \item $x + (y + z) = (x + y) + z$
    \item $x \cdot (y \cdot z) = (x \cdot y) \cdot z$
    \item $x \cdot (y + z) = x \cdot y + x \cdot z$
    \item $x + y = y + x$
    \item $x \cdot y = y \cdot x$
    \item $x \dot{-} (y + z) = (x \dot{-} y) \dot{-} z$
    \item $2^{x + y} = 2^x \cdot 2^y$
  \end{enumerate}
\end{lemma}

\begin{proof}
$ $

  \begin{enumerate}
    \item This is self-evident.
    \item If $z = 0$, then $x + y = x + y$. If $z = z' + 1$, then, by applying the IH and the relevant axioms:
    \begin{center}
      $(x + (y + (z' + 1))) = (x + ((y + z') + 1)) = (x + (y + z')) + 1 = ((x + y) + z') + 1 = (x + y) + (z' + 1)$
    \end{center}
    \item If $z = 0$, then $x \cdot (y \cdot 0) = (x \cdot y) \cdot 0$. If $z = z' + 1$, then:
    \begin{center}
    $x \cdot (y \cdot (z' + 1)) = x \cdot (y \cdot z' + y) = x \cdot (y \cdot z') + x \cdot y =
    (x \cdot y) \cdot z' + x \cdot y = (x \cdot y) \cdot (z' + 1)$
    \end{center}
    \item The rest of the cases are shown by induction on $z$. Consider the exponentiation law.
    If $y = 0$, then

    \begin{center}
    $2^{x + 0} = 2^{x} = 0 + 2^{x} = 2^{x} \cdot 0 + 2^{x} = 2^{x} \cdot (0 + 1) = 2^x \cdot 2^0$
    \end{center}

    If $y = y' + 1$, then:
    \begin{center}
      $2^{x + (y' + 1)} = 2^{(x + y') + 1} = 2^x \cdot 2^y + 2^x \cdot 2^y = 2^{x} \cdot 2^{y + 1}$
    \end{center}
  \end{enumerate}
\end{proof}

\begin{lemma}
  ${\bf I}\Delta_0(\operatorname{exp})$ proves (the universal closures of):

  \begin{enumerate}
    \item $\neg x < 0$
    \item $x \leq 0 \leftrightarrow x = 0$
    \item $0 \leq x$
    \item $x \leq x$
    \item $x < x + 1$
    \item $x < y + 1 \leftrightarrow x \leq y$
    \item $x \leq y \leftrightarrow x < y \lor x = y$ 
    \item $x \leq y \land y \leq z \to x \leq z$
    \item $x < y \land y < z \to x < z$
    \item $x \leq y \lor y < x$
    \item $x < y \to x + z < y + z$
    \item $x < y \to x \cdot (z + 1) < y \cdot (z + 1)$
    \item $x < 2^x$
    \item $x < y \to 2^x < 2^y$
  \end{enumerate}
\end{lemma}

\begin{proof}
  Straightforward induction.
\end{proof}

\begin{definition}
  A function $f : \mathbb{N}^k \to \mathbb{N}$ is \emph{provably $\Sigma_1$} or \emph{provably recursive}
  in an arithmetical theory if there is a $\Sigma_1$ formula $F(\vec{x}, y)$, a ``defining formula'' of $f$, such that:
  \begin{enumerate}
    \item $f(\vec{n}) = m$ iff $\omega \models f(\vec{n}) = m$
    \item $T \vdash \exists y F(\vec{x}, y)$
    \item $T \vdash F(\vec{x}, y) \land F(\vec{x}, y') \to y = y'$
  \end{enumerate}
\end{definition}
If a defining formula $F \in \Delta_0$, then a function $f$ is \emph{provably bounded} 
in $T$ if there is a term $t(\vec{x})$ such that $T \vdash F(\vec{x}, y) \to y < t(\vec{x})$.

\begin{theorem}
  Let $f$ be a provably recursive in $T$, then we can conservatively extend $T$
  by adding a new function symbol $f$ along with the defining axiom $F(\vec{x}, f(\vec{x}))$.
\end{theorem}

\begin{proof}
  Let $\mathcal{M} \models T$, $\mathcal{M}$ can be made into a model $(\mathcal{M}, f)$ where
  we interpret $f$ as the function which is uniquely determined by the second and third conditions
  of the definitions above.
  Let $\varphi$ be a statement not involving $f$ such that $\varphi$ is true
  in $(\mathcal{M}, f)$, so $\varphi$ is true in $\mathcal{M}$ as well.
  By compactness $T$ proves $\varphi$.
\end{proof}

\begin{lemma}
  Each term defines a provably bounded function of ${\bf I}\Delta_0(\operatorname{exp})$.
\end{lemma}
\begin{proof}
  Let $f$ be a function defined by some ${\bf I}\Delta_0(\operatorname{exp})$-term $t$, 
  that is, $f(\vec{x}) = t(\vec{x})$.
  Take $y = t(\vec{x})$ as the defining formula for $f$ since 
  $\exists y \: (y = t(\vec{x}))$ is derivable.
  If $y' = t(\vec{x}) \land y = t(\vec{x})$, then $y = y'$ by transitivity.
  A formula $y = t(\vec{x})$ is bounded and $y = t$ implies $y < t + 1$.
  Thus $f$ is provably bounded.
\end{proof}

\begin{lemma}~\label{upper:bound:elem}
  Define $2_k(x)$ as $2_0(x) = x$ and $2_{n + 1}(x) = 2^{2_n(x)}$. 
  Then for every term $t(x_1, \dots, x_n)$ built up from the constants $0, S, P, +, \dot{-}, \cdot, exp_2$ there exists $k < \omega$ such that:
  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash t(x_1, \dots, x_n) < 2_k(\sum \limits_{k = 0}^n x_k)$
  \end{center}
\end{lemma}

\begin{proof}
Let $t$ be a term constructed from subterms $t_0$ and $t_1$ by using one of the function constants.
Assume that inductively $t_0 < 2_{k_0}(s_0)$ and $t_1 < 2_{k_1}(s_1)$ are both provable for some $k_0, k_1 < \omega$, where
$s_i$ is the sum of the variables of $t_i$ for $i = 0, 1$.

Let $s$ be the sum of all variables appearing in either $t_0$ or $t_1$ and let $k = \max(k_0, k_1)$.
Then one can prove $t_0 < 2_{k}(s)$ and $t_1 < 2_{k}(s)$. So one needs to show the following:
\begin{enumerate}
  \item $t_0 + 1 < 2_{k + 1}(s)$
  \item $t_0 \dot{-} 1 < 2_{k}(s)$
  \item $t_0 \dot{-} t_1 < 2_{k}(s)$
  \item $t_0 \cdot t_1 < 2_{k}(s)$
  \item $t_0 + t_1 < 2_{k}(s)$
  \item $2^{t_0} < 2_{k}(s)$
\end{enumerate}
So ${\bf I}\Delta_0(\operatorname{exp}) \vdash t < 2_{k + 1}(s)$.
\end{proof}

\begin{lemma}
  Let $f$ be a function defined by composition:
  \begin{center}
    $f(\vec{x}) = g_0(g_1(\vec{x}), \dots, g_m(\vec{x}))$
  \end{center}
  where $g_0, g_1, \dots, g_m$ are functions each of which is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
  Then $f$ is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
\end{lemma}

\begin{proof}
  Each $g_i$ has a defining formula $G_i$ and, by Lemma~\ref{upper:bound:elem}, there is a number $k_i < \omega$ such that:
  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash \exists y < 2_{k_i}(s) G_i (\vec{x}, y)$
  \end{center}
  where $s$ is the sum of elements of $\vec{x}$. And for $i = 0$ one has:
  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash \exists y < 2_{k_0}(s_0) G_0 (y_1, \dots, y_m, y)$
  \end{center}
  where $s_0$ is the sum of $y_1, \dots, y_m$.

  Let $k = \max \{ k_i < \omega \: | \: i < m + 1 \}$ and let $F(\vec{x}, y)$ be the bounded formula:
  \begin{center}
    $\exists y_1 < 2_{k}(s) \dots \exists y_m < 2_{k}(s) C(\vec{x}, y_1, \dots, y_m, y)$
  \end{center}
  where $C(\vec{x}, y_1, \dots, y_m, y)$ is the conjunction:
  \begin{center}
    $G_1(\vec{x}, y_1) \land \dots \land G_m(\vec{x}, y_m) \land G_0 (y_1, \dots, y_m, y)$
  \end{center}

  $F$ is clearly a defining formula for $f$ such that ${\bf I}\Delta_0(\operatorname{exp}) \vdash \exists y F(\vec{x}, y)$.

  Moreover, each $G_i$ is unique, so ${\bf I}\Delta_0(\operatorname{exp})$ also proves:

  \vspace{\baselineskip}

  $\begin{array}{lll}
    & C(\vec{x}, y_1, \dots, y_m, y) \land C(\vec{x}, z_1, \dots, z_m, z) \to & \\
    & \to \bigwedge \limits_{j = 1}^m y_j = z_j \land G_0(y_1, \dots, y_m, y) \land G_0(y_1, \dots, y_m, z) \to & \\
    & \to y = z&
  \end{array}$

  \vspace{\baselineskip}

  so we have (by first order logic):
  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash F(\vec{x}, y) \land F(\vec{x}, z) \to y = z$
  \end{center}

  Thus $f$ is provably $\Sigma_1$ in ${\bf I}\Delta_0(\operatorname{exp})$, so the rest is to find its bounding term.

  ${\bf I}\Delta_0(\operatorname{exp})$ proves the following:

  \begin{center}
    $C(\vec{x}, y_1, \dots, y_m, y) \to \bigwedge \limits_{j = 1}^m y_j < 2_k(s) \land y < 2_k(y_1 + \dots + y_m)$
  \end{center}

  and

  \begin{center}
    $\bigwedge \limits_{j = 1}^m y_j < 2_k(s) \to y_1 + \dots + y_m < 2_k(s) \cdot m$
  \end{center}

  Put $t(\vec{x}) = 2_k(2_k(s) \cdot m)$, then we obtain

  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash C(\vec{x}, y_1, \dots, y_m, y) \to y < t(\vec{x})$
  \end{center}

  and so

  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash F(\vec{x}, y) \to y < t(\vec{x})$
  \end{center}
\end{proof}

\begin{lemma}
  Suppose $f$ is defined by bounded minimisation
  \begin{center}
    $f(\vec{n}, m) = \mu_{k < m} (g(\vec{n}, k) = 0)$
  \end{center}
  from a function $g$ which is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
  Then $f$ is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
\end{lemma}

\begin{proof}
   Let $G$ be a defining formula for $g$. Let $F(\vec{x}, z, y)$ be the bounded formula
   \begin{center}
    $y \leq z \land \forall i < y \neg G(\vec{x}, i, 0) \land (y = z \lor G(\vec{x}, y, 0))$
   \end{center}

   $\omega \models F(\vec{n}, m, k)$ iff either $k$ is the least number less than $m$ such that $g(\vec{n}, k) = 0$ or 
   there is no such and $k = m$. Thus it means that $k$ is the value of $f(\vec{n}, m)$, so $F$ is a defining formula for $f$.

   Furthermore
   \begin{center}
   ${\bf I}\Delta_0(\operatorname{exp}) \vdash F(\vec{x}, z, y) \to y < z + 1$
   \end{center}
   so $t(\vec{x}, z) = z + 1$ can be taken as a bounding term for $f$.

   We can prove:
   \begin{center}
    $F(\vec{x}, z, y) \land F(\vec{x}, z, y') \land y < y' \to G(\vec{x}, y, 0) \land \neg G(\vec{x}, y, 0)$
   \end{center}
   and similarly for interchanged $y$ and $y'$. So we can prove:
   \begin{center}
    $F(\vec{x}, z, y) \land F(\vec{x}, z, y') \to \neg y < y' \land \neg y' < y$
   \end{center}
   As far as $y < y' \lor y' < y \lor y = y'$, we have
   \begin{center}
    $F(\vec{x}, z, y) \land F(\vec{x}, z, y') \to y = y'$
   \end{center}

   Now we have to check that ${\bf I}\Delta_0(\operatorname{exp}) \vdash \exists y F(\vec{x}, z, y)$.
   We construct such $y$ by bounded induction on $z$.

   \begin{enumerate}
    \item $z = 0$.

    $F(\vec{x}, 0, 0)$ is provable since $y = 0 \leftrightarrow y \leq 0$ and $\neg i < 0$. 
    So ${\bf I}\Delta_0(\operatorname{exp}) \vdash F(\vec{x}, 0, y)$ is provable.
    \item Assume $\exists y F(\vec{x}, z, y)$ is provable, let show that that $\exists y F(\vec{x}, z + 1, y)$ is provable.

    We can show $y \leq z \to y + 1 \leq z + 1$ and, via $i < y + 1 \leftrightarrow i < y \lor i = y$,
    \begin{center}
      $\forall i < y \: \neg G(\vec{x}, i, 0) \land ((y = z) \land \neg G(\vec{x}, y, 0)) \to \forall i < y + 1 \: \neg G(\vec{x}, i, 0) \land y + 1 = z + 1$
    \end{center}
    Therefore
    \begin{center}
    $F(\vec{x}, z, y) \to F(\vec{x}, z + 1, y + 1) \lor F(\vec{x}, z + 1, y)$
    \end{center}
    and thus:
    \begin{center}
      $\exists y F(\vec{x}, z, y) \to \exists y F(\vec{x}, z + 1, y)$
    \end{center}
   \end{enumerate}
\end{proof}

\begin{theorem}
  Every elementary function is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
\end{theorem}

\begin{proof}
  As we know from recursion theory, the class of elementary functions can be characterised
  as those functions which are definable from $0$, $S$, $P$, $\cdot$, $+$, $exp_2$, $\dot{-}$ and $\cdot$
  by composition and minimisation. And then we apply above lemmas.
\end{proof}

\subsection{Proof-theoretic Characterisation}

For this section we shall be using a Tait-style formalisation of ${\bf I}\Delta_0(\operatorname{exp})$.
We have the following logical rules:

\vspace{\baselineskip}

\begin{prooftree}
  \AxiomC{$ $}
  \RightLabel{{\bf Ax}}
  \UnaryInfC{$\Gamma, R\vec{t}, \neg R\vec{t}$}
\end{prooftree}
\begin{minipage}{0.45\textwidth}
  \begin{prooftree}
    \AxiomC{$\Gamma, A_0, A_1$}
    \RightLabel{$\vee$}
    \UnaryInfC{$\Gamma, A_0 \vee A_1$}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{$\Gamma, A(t)$}
    \RightLabel{$\exists$}
    \UnaryInfC{$\Gamma, \exists x A(x)$}
  \end{prooftree}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
  \begin{prooftree}
    \AxiomC{$\Gamma, A_0$}
    \AxiomC{$\Gamma, A_1$}
    \RightLabel{$\land$}
    \BinaryInfC{$\Gamma, A_0 \land A_1$}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{$\Gamma, A$}
    \RightLabel{$\forall$}
    \UnaryInfC{$\Gamma, \forall x A$}
  \end{prooftree}
\end{minipage}

\vspace{\baselineskip}

where $R\vec{t}$ is an atomic formula and $x$ is not free in $A$ in the $\forall$ rule.
Here $\Gamma$ stores all non-logical axioms of ${\bf I}\Delta_0(\exp)$ along with its negations.
We also have the bounded induction rule:
  \begin{prooftree}
    \AxiomC{$\Gamma, B(0)$}
    \AxiomC{$\Gamma, \neg B(n), B(n + 1)$}
    \BinaryInfC{$\Gamma, B(t)$}
  \end{prooftree}
where $B$ is a bounded formula and $t$ is any term. 

Of course, the cut rule is admissible:
  \begin{prooftree}
    \AxiomC{$\Gamma, A$}
    \AxiomC{$\Gamma, \neg A$}
    \RightLabel{${\bf cut}$}
    \BinaryInfC{$\Gamma$}
  \end{prooftree}

\section{Primitive Recursion and ${\bf I}\Sigma_1$}

${\bf I}\Sigma_1$ is an arithmetical theory where the induction scheme is
restructed to $\Sigma_1$ formulas.

\begin{lemma}
  Every primitive recursion is provably recursive in ${\bf I}\Sigma_1$.
\end{lemma}

\begin{proof}
  We have to show represent each primitive recursive function $f$ with a $\Sigma_1$ formula 
  $F(\vec{x}, y) := \exists z C(\vec{x}, y, z)$ such that:
  \begin{enumerate}
    \item $f(\vec{n}) = m$ iff $\omega \models F(\vec{x}, y)$.
    \item ${\bf I}\Sigma_1 \vdash \exists y F(\vec{x}, y)$.
    \item ${\bf I}\Sigma_1 \vdash F(\vec{x}, y) \land F(\vec{x}, y') \to y = y'$.
  \end{enumerate}

\end{proof}


\bibliographystyle{alpha}
\bibliography{Text}

\end{document}