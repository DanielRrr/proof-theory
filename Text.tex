\documentclass[8pt]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsopn}
\usepackage{comment}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{bussproofs}
\usepackage[all, 2cell]{xy}
\usepackage[all]{xy}
\usepackage{rotating}
\usepackage{lscape}
\usepackage{minted}


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]

\theoremstyle{definition}
\newtheorem{claim}{Claim}[section]

\theoremstyle{definition}
\newtheorem{ex}{Example}[section] 

\theoremstyle{definition}
\newtheorem{cons}{Construction}[section] 

\theoremstyle{definition}
\newtheorem{rem}{Remark}[section] 


\theoremstyle{definition}
\newtheorem{prop}{Proposition}[section]

\theoremstyle{definition}
\newtheorem{lemma}{Lemma}[section]

\theoremstyle{definition}
\newtheorem{fact}{Fact}[section]

\theoremstyle{definition}
\newtheorem{remark}{Remark}[section]

\theoremstyle{definition}
\newtheorem{notation}{Notation}[section]

\theoremstyle{definition}
\newtheorem{example}{Example}[section]

\theoremstyle{definition}
\newtheorem{col}{Corollary}[section]

\theoremstyle{question}
\newtheorem{question}{Question}

\let\strokeL\L
\renewcommand\L{\mathbf{L}}

\title{Some Notes on Proof Theory and Elements of Ordinal Analysis}
\author{Daniel Rogozin}
\date{ }

\begin{document}

\maketitle

\section{Provable Recursion in ${\bf I}\Delta_0(\operatorname{exp})$}

${\bf I}\Delta_0(\operatorname{exp})$ is a theory in first-order logic in the language:
\begin{center}
  $\{ =, 0, S, P, +, \dot{-}, \cdot, exp_2 \}$
\end{center}
where $S$ and $P$ are successor and precessor functions respectively.
Further, we will denote $S(x)$ and $P(x)$ as $x + 1$ and $x \dot{-} 1$ respectively.
$2^x$ stands for $exp_2(x)$.

The non-logical axioms of ${\bf I}\Delta_0(\operatorname{exp})$ are the following list:

\vspace{\baselineskip}

\begin{minipage}{0.45\textwidth}
  \begin{itemize}
    \item $x + 1 \neq 0$
    \item $0 \dot{-} 1 = 0$
    \item $x + 0 = x$
    \item $x \dot{-} 0 = x$
    \item $x \cdot 0 = 0$
    \item $2^0 = 1$
  \end{itemize}
\end{minipage}%
\hfill
\begin{minipage}{0.45\textwidth}
  \begin{itemize}
    \item $x + 1 = y + 1 \to x = y$
    \item $(x + 1) \dot{-} 1 = x$
    \item $x + (y + 1) = (x + y) + 1$
    \item $x \dot{-} (y + 1) = x \dot{-} y \dot{-} 1$
    \item $x \cdot (y + 1) = x \cdot y + x$
    \item $2^{x + 1} = 2^x + 2^x$
  \end{itemize}
\end{minipage}

\vspace{\baselineskip}

along with the bounded induction scheme:
\begin{center}
  $B(0) \land \forall x (B (x) \to B(x + 1)) \to \forall x B(x)$
\end{center}
where $B$ is a \emph{$\Delta$-formula}, that is a formula one of the following forms (with bounded quantifiers only):
\begin{itemize}
  \item $B \eqcirc \forall x < t P(x) \equiv \forall x (x < t \to P(x))$ 
  \item $B \eqcirc \exists x < t P(x) \equiv \exists x (x < t \land P(x))$
\end{itemize}

A $\Sigma_1$-formula is a formula of the form:
\begin{center}
  $\exists \vec{x} B(\vec{x})$
\end{center}
where $B(\vec{x}) \in \Delta_0$.

\begin{lemma}
  ${\bf I}\Delta_0(\operatorname{exp})$ proves (the universal closures of):
  \begin{enumerate}
    \item $x = 0 \lor x = (x \dot{-} 1) + 1$
    \item $x + (y + z) = (x + y) + z$
    \item $x \cdot (y \cdot z) = (x \cdot y) \cdot z$
    \item $x \cdot (y + z) = x \cdot y + x \cdot z$
    \item $x + y = y + x$
    \item $x \cdot y = y \cdot x$
    \item $x \dot{-} (y + z) = (x \dot{-} y) \dot{-} z$
    \item $2^{x + y} = 2^x \cdot 2^y$
  \end{enumerate}
\end{lemma}

\begin{proof}
$ $

  \begin{enumerate}
    \item This is self-evident.
    \item If $z = 0$, then $x + y = x + y$. If $z = z' + 1$, then, by applying the IH and the relevant axioms:
    \begin{center}
      $(x + (y + (z' + 1))) = (x + ((y + z') + 1)) = (x + (y + z')) + 1 = ((x + y) + z') + 1 = (x + y) + (z' + 1)$
    \end{center}
    \item If $z = 0$, then $x \cdot (y \cdot 0) = (x \cdot y) \cdot 0$. If $z = z' + 1$, then:
    \begin{center}
    $x \cdot (y \cdot (z' + 1)) = x \cdot (y \cdot z' + y) = x \cdot (y \cdot z') + x \cdot y =
    (x \cdot y) \cdot z' + x \cdot y = (x \cdot y) \cdot (z' + 1)$
    \end{center}
    \item The rest of the cases are shown by induction on $z$. Consider the exponentiation law.
    If $y = 0$, then

    \begin{center}
    $2^{x + 0} = 2^{x} = 0 + 2^{x} = 2^{x} \cdot 0 + 2^{x} = 2^{x} \cdot (0 + 1) = 2^x \cdot 2^0$
    \end{center}

    If $y = y' + 1$, then:
    \begin{center}
      $2^{x + (y' + 1)} = 2^{(x + y') + 1} = 2^x \cdot 2^y + 2^x \cdot 2^y = 2^{x} \cdot 2^{y + 1}$
    \end{center}
  \end{enumerate}
\end{proof}

\begin{lemma}
  ${\bf I}\Delta_0(\operatorname{exp})$ proves (the universal closures of):

  \begin{enumerate}
    \item $\neg x < 0$
    \item $x \leq 0 \leftrightarrow x = 0$
    \item $0 \leq x$
    \item $x \leq x$
    \item $x < x + 1$
    \item $x < y + 1 \leftrightarrow x \leq y$
    \item $x \leq y \leftrightarrow x < y \lor x = y$ 
    \item $x \leq y \land y \leq z \to x \leq z$
    \item $x < y \land y < z \to x < z$
    \item $x \leq y \lor y < x$
    \item $x < y \to x + z < y + z$
    \item $x < y \to x \cdot (z + 1) < y \cdot (z + 1)$
    \item $x < 2^x$
    \item $x < y \to 2^x < 2^y$
  \end{enumerate}
\end{lemma}

\begin{proof}
  Straightforward induction.
\end{proof}

\begin{definition}
  A function $f : \mathbb{N}^k \to \mathbb{N}$ is \emph{provably $\Sigma_1$} or \emph{provably recursive}
  in an arithmetical theory if there is a $\Sigma_1$ formula $F(\vec{x}, y)$, a ``defining formula'' of $f$, such that:
  \begin{enumerate}
    \item $f(\vec{n}) = m$ iff $\omega \models f(\vec{n}) = m$
    \item $T \vdash \exists y F(\vec{x}, y)$
    \item $T \vdash F(\vec{x}, y) \land F(\vec{x}, y') \to y = y'$
  \end{enumerate}
\end{definition}
If a defining formula $F \in \Delta_0$, then a function $f$ is \emph{provably bounded} 
in $T$ if there is a term $t(\vec{x})$ such that $T \vdash F(\vec{x}, y) \to y < t(\vec{x})$.

\begin{theorem}
  Let $f$ be a provably recursive in $T$, then we can conservatively extend $T$
  by adding a new function symbol $f$ along with the defining axiom $F(\vec{x}, f(\vec{x}))$.
\end{theorem}

\begin{proof}
  Let $\mathcal{M} \models T$, $\mathcal{M}$ can be made into a model $(\mathcal{M}, f)$ where
  we interpret $f$ as the function which is uniquely determined by the second and third conditions
  of the definitions above.
  Let $\varphi$ be a statement not involving $f$ such that $\varphi$ is true
  in $(\mathcal{M}, f)$, so $\varphi$ is true in $\mathcal{M}$ as well.
  By compactness $T$ proves $\varphi$.
\end{proof}

\begin{lemma}
  Each term defines a provably bounded function of ${\bf I}\Delta_0(\operatorname{exp})$.
\end{lemma}
\begin{proof}
  Let $f$ be a function defined by some ${\bf I}\Delta_0(\operatorname{exp})$-term $t$, 
  that is, $f(\vec{x}) = t(\vec{x})$.
  Take $y = t(\vec{x})$ as the defining formula for $f$ since 
  $\exists y \: (y = t(\vec{x}))$ is derivable.
  If $y' = t(\vec{x}) \land y = t(\vec{x})$, then $y = y'$ by transitivity.
  A formula $y = t(\vec{x})$ is bounded and $y = t$ implies $y < t + 1$.
  Thus $f$ is provably bounded.
\end{proof}

\begin{lemma}~\label{upper:bound:elem}
  Define $2_k(x)$ as $2_0(x) = x$ and $2_{n + 1}(x) = 2^{2_n(x)}$. 
  Then for every term $t(x_1, \dots, x_n)$ built up from the constants $0, S, P, +, \dot{-}, \cdot, exp_2$ there exists $k < \omega$ such that:
  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash t(x_1, \dots, x_n) < 2_k(\sum \limits_{k = 0}^n x_k)$
  \end{center}
\end{lemma}

\begin{proof}
Let $t$ be a term constructed from subterms $t_0$ and $t_1$ by using one of the function constants.
Assume that inductively $t_0 < 2_{k_0}(s_0)$ and $t_1 < 2_{k_1}(s_1)$ are both provable for some $k_0, k_1 < \omega$, where
$s_i$ is the sum of the variables of $t_i$ for $i = 0, 1$.

Let $s$ be the sum of all variables appearing in either $t_0$ or $t_1$ and let $k = \max(k_0, k_1)$.
Then one can prove $t_0 < 2_{k}(s)$ and $t_1 < 2_{k}(s)$. So one needs to show the following:
\begin{enumerate}
  \item $t_0 + 1 < 2_{k + 1}(s)$
  \item $t_0 \dot{-} 1 < 2_{k}(s)$
  \item $t_0 \dot{-} t_1 < 2_{k}(s)$
  \item $t_0 \cdot t_1 < 2_{k}(s)$
  \item $t_0 + t_1 < 2_{k}(s)$
  \item $2^{t_0} < 2_{k}(s)$
\end{enumerate}
So ${\bf I}\Delta_0(\operatorname{exp}) \vdash t < 2_{k + 1}(s)$.
\end{proof}

\begin{lemma}
  Let $f$ be a function defined by composition:
  \begin{center}
    $f(\vec{x}) = g_0(g_1(\vec{x}), \dots, g_m(\vec{x}))$
  \end{center}
  where $g_0, g_1, \dots, g_m$ are functions each of which is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
  Then $f$ is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
\end{lemma}

\begin{proof}
  Each $g_i$ has a defining formula $G_i$ and, by Lemma~\ref{upper:bound:elem}, there is a number $k_i < \omega$ such that:
  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash \exists y < 2_{k_i}(s) \: G_i (\vec{x}, y)$
  \end{center}
  where $s$ is the sum of elements of $\vec{x}$. And for $i = 0$ one has:
  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash \exists y < 2_{k_0}(s_0) \: G_0 (y_1, \dots, y_m, y)$
  \end{center}
  where $s_0$ is the sum of $y_1, \dots, y_m$.

  Let $k = \max \{ k_i < \omega \: | \: i < m + 1 \}$ and let $F(\vec{x}, y)$ be the bounded formula:
  \begin{center}
    $\exists y_1 < 2_{k}(s) \: \dots \: \exists y_m < 2_{k}(s) \: C(\vec{x}, y_1, \dots, y_m, y)$
  \end{center}
  where $C(\vec{x}, y_1, \dots, y_m, y)$ is the conjunction:
  \begin{center}
    $G_1(\vec{x}, y_1) \land \dots \land G_m(\vec{x}, y_m) \land G_0 (y_1, \dots, y_m, y)$
  \end{center}

  $F$ is clearly a defining formula for $f$ such that ${\bf I}\Delta_0(\operatorname{exp}) \vdash \exists y F(\vec{x}, y)$.

  Moreover, each $G_i$ is unique, so ${\bf I}\Delta_0(\operatorname{exp})$ also proves:

  \vspace{\baselineskip}

  $\begin{array}{lll}
    & C(\vec{x}, y_1, \dots, y_m, y) \land C(\vec{x}, z_1, \dots, z_m, z) \to & \\
    & \to \bigwedge \limits_{j = 1}^m y_j = z_j \land G_0(y_1, \dots, y_m, y) \land G_0(y_1, \dots, y_m, z) \to & \\
    & \to y = z&
  \end{array}$

  \vspace{\baselineskip}

  so we have (by first order logic):
  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash F(\vec{x}, y) \land F(\vec{x}, z) \to y = z$
  \end{center}

  Thus $f$ is provably $\Sigma_1$ in ${\bf I}\Delta_0(\operatorname{exp})$, so the rest is to find its bounding term.

  ${\bf I}\Delta_0(\operatorname{exp})$ proves the following:

  \begin{center}
    $C(\vec{x}, y_1, \dots, y_m, y) \to \bigwedge \limits_{j = 1}^m y_j < 2_k(s) \land y < 2_k(y_1 + \dots + y_m)$
  \end{center}

  and

  \begin{center}
    $\bigwedge \limits_{j = 1}^m y_j < 2_k(s) \to y_1 + \dots + y_m < 2_k(s) \cdot m$
  \end{center}

  Put $t(\vec{x}) = 2_k(2_k(s) \cdot m)$, then we obtain

  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash C(\vec{x}, y_1, \dots, y_m, y) \to y < t(\vec{x})$
  \end{center}

  and so

  \begin{center}
    ${\bf I}\Delta_0(\operatorname{exp}) \vdash F(\vec{x}, y) \to y < t(\vec{x})$
  \end{center}
\end{proof}

\begin{lemma}
  Suppose $f$ is defined by bounded minimisation
  \begin{center}
    $f(\vec{n}, m) = \mu_{k < m} (g(\vec{n}, k) = 0)$
  \end{center}
  from a function $g$ which is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
  Then $f$ is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
\end{lemma}

\begin{proof}
   Let $G$ be a defining formula for $g$. Let $F(\vec{x}, z, y)$ be the bounded formula
   \begin{center}
    $y \leq z \land \forall i < y \neg G(\vec{x}, i, 0) \land (y = z \lor G(\vec{x}, y, 0))$
   \end{center}

   $\omega \models F(\vec{n}, m, k)$ iff either $k$ is the least number less than $m$ such that $g(\vec{n}, k) = 0$ or 
   there is no such and $k = m$. Thus it means that $k$ is the value of $f(\vec{n}, m)$, so $F$ is a defining formula for $f$.

   Furthermore
   \begin{center}
   ${\bf I}\Delta_0(\operatorname{exp}) \vdash F(\vec{x}, z, y) \to y < z + 1$
   \end{center}
   so $t(\vec{x}, z) = z + 1$ can be taken as a bounding term for $f$.

   We can prove:
   \begin{center}
    $F(\vec{x}, z, y) \land F(\vec{x}, z, y') \land y < y' \to G(\vec{x}, y, 0) \land \neg G(\vec{x}, y, 0)$
   \end{center}
   and similarly for interchanged $y$ and $y'$. So we can prove:
   \begin{center}
    $F(\vec{x}, z, y) \land F(\vec{x}, z, y') \to \neg y < y' \land \neg y' < y$
   \end{center}
   As far as $y < y' \lor y' < y \lor y = y'$, we have
   \begin{center}
    $F(\vec{x}, z, y) \land F(\vec{x}, z, y') \to y = y'$
   \end{center}

   Now we have to check that ${\bf I}\Delta_0(\operatorname{exp}) \vdash \exists y F(\vec{x}, z, y)$.
   We construct such $y$ by bounded induction on $z$.

   \begin{enumerate}
    \item $z = 0$.

    $F(\vec{x}, 0, 0)$ is provable since $y = 0 \leftrightarrow y \leq 0$ and $\neg i < 0$. 
    So ${\bf I}\Delta_0(\operatorname{exp}) \vdash F(\vec{x}, 0, y)$ is provable.
    \item Assume $\exists y F(\vec{x}, z, y)$ is provable, let show that that $\exists y F(\vec{x}, z + 1, y)$ is provable.

    We can show $y \leq z \to y + 1 \leq z + 1$ and, via $i < y + 1 \leftrightarrow i < y \lor i = y$,
    \begin{center}
      $\forall i < y \: \neg G(\vec{x}, i, 0) \land ((y = z) \land \neg G(\vec{x}, y, 0)) \to \forall i < y + 1 \: \neg G(\vec{x}, i, 0) \land y + 1 = z + 1$
    \end{center}
    Therefore
    \begin{center}
    $F(\vec{x}, z, y) \to F(\vec{x}, z + 1, y + 1) \lor F(\vec{x}, z + 1, y)$
    \end{center}
    and thus:
    \begin{center}
      $\exists y F(\vec{x}, z, y) \to \exists y F(\vec{x}, z + 1, y)$
    \end{center}
   \end{enumerate}
\end{proof}

\begin{theorem}~\label{provablysigma1:1}
  Every elementary function is provably bounded in ${\bf I}\Delta_0(\operatorname{exp})$.
\end{theorem}

\begin{proof}
  As we know from recursion theory, the class of elementary functions can be characterised
  as those functions which are definable from $0$, $S$, $P$, $\cdot$, $+$, $exp_2$, $\dot{-}$ and $\cdot$
  by composition and minimisation. And then we apply above lemmas.
\end{proof}

\subsection{Proof-theoretic Characterisation}

For this section we shall be using a Tait-style formalisation of ${\bf I}\Delta_0(\operatorname{exp})$.
We have the following logical rules:

\vspace{\baselineskip}

\begin{prooftree}
  \AxiomC{$ $}
  \RightLabel{{\bf Ax}}
  \UnaryInfC{$\Gamma, R\vec{t}, \neg R\vec{t}$}
\end{prooftree}
\begin{minipage}{0.45\textwidth}
  \begin{prooftree}
    \AxiomC{$\Gamma, A_0, A_1$}
    \RightLabel{$\vee$}
    \UnaryInfC{$\Gamma, A_0 \vee A_1$}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{$\Gamma, A(t)$}
    \RightLabel{$\exists$}
    \UnaryInfC{$\Gamma, \exists x A(x)$}
  \end{prooftree}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
  \begin{prooftree}
    \AxiomC{$\Gamma, A_0$}
    \AxiomC{$\Gamma, A_1$}
    \RightLabel{$\land$}
    \BinaryInfC{$\Gamma, A_0 \land A_1$}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{$\Gamma, A$}
    \RightLabel{$\forall$}
    \UnaryInfC{$\Gamma, \forall x A$}
  \end{prooftree}
\end{minipage}

\vspace{\baselineskip}

where $R\vec{t}$ is an atomic formula and $x$ is not free in $A$ in the $\forall$ rule.
Here $\Gamma$ stores all non-logical axioms of ${\bf I}\Delta_0(\exp)$ along with its negations.
We also have the bounded induction rule:
  \begin{prooftree}
    \AxiomC{$\Gamma, B(0)$}
    \AxiomC{$\Gamma, \neg B(n), B(n + 1)$}
    \RightLabel{${\bf BInd}$}
    \BinaryInfC{$\Gamma, B(t)$}
  \end{prooftree}
where $B$ is a bounded formula and $t$ is any term. 

Of course, the cut rule is admissible:
  \begin{prooftree}
    \AxiomC{$\Gamma, A$}
    \AxiomC{$\Gamma, \neg A$}
    \RightLabel{${\bf cut}$}
    \BinaryInfC{$\Gamma$}
  \end{prooftree}


\begin{definition}
  Let $\exists \vec{z} B(\vec{z})$ be a closed $\Sigma_1$-formula, then it is \emph{true at $m$}, written as 
  $m \models \exists \vec{z} B(\vec{z})$, if there exist natural numbers $m_1, \dots, m_l$ such that each 
  $m_i < m$ and $B(\vec{m})$ is true in the standard model.

  A finite set $\Gamma$ of closed $\Sigma_1$-formulas is true at $m$, written as $m \models \Gamma$ if at least one of them is true at $m$.
\end{definition}

If $\Gamma(x_1, \dots, x_k)$ is a finite set of $\Sigma_1$-formulas whose free variables occur amongst $x_1, \dots, x_k$.
Let $f : \mathbb{N}^{k} \to \mathbb{N}$, then $f \models \Gamma(x_1, \dots, x_k)$ we have $f(\vec{n}) \models \Gamma(x_1 := n_1, \dots, x_k := n_k)$
for each $\vec{n} = (n_1, \dots, n_k)$.

\begin{fact} {\bf (Persistence)}

  \begin{enumerate}
    \item If $m \leq m'$, then $m \models \exists \vec{z} B(\vec{z})$ implies $m' \models \exists \vec{z} B(\vec{z})$.
    \item If $\forall \vec{n} \in \mathbb{N}^{k}$ $f(\vec{n}) \leq f'(\vec{n})$, 
    then $f(\vec{n}) \models \Gamma(x_1 := n_1, \dots, x_k := n_k)$ implies $f'(\vec{n}) \models \Gamma(x_1 := n_1, \dots, x_k := n_k)$.
  \end{enumerate}
\end{fact}

\begin{lemma}~\label{truth:idelta0}
  Let $\Gamma(\vec{x})$ be a finite set of $\Sigma_1$ formulas such that 
  \begin{center}
  ${\bf I}\Delta_0(exp) \vdash \bigvee \limits_{\gamma(\vec{x}) \in \Gamma(\vec{x})} \gamma(\vec{x})$.
  \end{center}
  Then there is an elementary function $f$ such that $f \models \Gamma(\vec{x})$ and $f$ is strongly increasing on its variables.
\end{lemma}

\begin{proof}

  If $\Gamma$ is provable in ${\bf I}\Delta_0(exp)$, 
  then it is provable in the Tait-style version of ${\bf I}\Delta_0(exp)$, where all cut formulas are $\Sigma_1$.

  If $\Gamma$ is classically derivable from non-logical axioms $A_1, \dots, A_s$, then there is a cut-free proof
  in the Tait calculus of $\neg A_1, \Delta, \Gamma$, where $\Delta = \neg A_2, \dots, \neg A_s$. Let us show how to cancel $\neg A_1$ using a $\Sigma_1$-cut.

  If $A_1$ is an induction axiom on some formula $B$, then we have a cut-free proof of:
  \begin{center}
    $B(0) \land \forall y (\neg B(y) \lor B(y + 1)) \land \exists x \neg B(x), \Delta, \Gamma$
  \end{center}

  Thus we also have cut-free proofs of $B(0), \Delta, \Gamma$, $\neg B(y), B(y + 1), \Delta, \Gamma$
  and $\exists x \neg B(x), \Delta, \Gamma$. So we have
  \begin{prooftree}
    \AxiomC{$\Delta, \Gamma, B(0)$}
    \AxiomC{$\Delta, \Gamma, \neg B(y), B(y + 1)$}
    \RightLabel{${\bf BInd}$}
    \BinaryInfC{$\Delta, \Gamma, B(x)$}
    \RightLabel{$\forall$}
    \UnaryInfC{$\Delta, \Gamma, \forall x B(x)$}
    \AxiomC{$\exists x \neg B(x), \Delta, \Gamma$}
    \RightLabel{$\Sigma_1$-{\bf cut}}
    \BinaryInfC{$\Delta, \Gamma$}
  \end{prooftree}

  We can similarly cancel each of $\neg A_2, \dots, \neg A_s$ and so obtain the proof of $\Gamma$ with $\Sigma_1$-cuts only.

  Now we choose a proof of $\Gamma(\vec{x})$ and proceed by induction on the height of the proof and determine
  an elementary function $f$ such that $f \models \Gamma$.

  \begin{enumerate}
    \item If $\Gamma(\vec{x})$ is an axiom, then for all $\vec{n}$ $\Gamma(\vec{n})$ contains a true atom.
    So for any $f$ $f \models \Gamma$. Let us choose $f(\vec{n}) = n_1 + \dots + n_k$.
    \item If $\Gamma, B_0 \vee B_1$ is derivable, so is $\Gamma, B_0, B_1$. Note that $B_0$ and $B_1$ are both bounded.
    Let $f \models \Gamma, B_0, B_1$, then $f \models \Gamma, B_0 \vee B_1$.
    \item Assume $\Gamma, B_0 \land B_1$ is derivable, then $\Gamma, B_0$ and $\Gamma, B_1$
    By the induction hypothesis we have $f_0 \models \Gamma, B_0$ and $f_1 \models \Gamma, B_1$, so, by persistence,
    we have $\lambda \vec{n}. f_0(\vec{n}) + f_1(\vec{n}) \models \Gamma, B_0 \land B_1$.
    \item Assume $\Gamma, \forall y B(y)$ is derivable, then $\Gamma, B(y)$ is derivable and $y$ is not free in $\Gamma$.
    Since all the formulas are $\Sigma_1$, $\forall x B(y)$ must be bounded, so $B(y) \eqcirc \neg (y < t) \lor B'(y)$ for some
    term $t$ and for some bounded formula $B'$.
    By the induction hypothesis, assume $f_0 \models \Gamma, \neg (y < t), B'(y)$ for some increasing elementary function $f_0$.
    Then we have:
    \begin{center}
      $f_0(\vec{n}, k) \models \Gamma(\vec{n}), \neg (k < t(\vec{n})), B'(\vec{n}, k)$
    \end{center}
    Let $g$ be an increasing elementary function bounding $t$, define
    \begin{center}
      $f(\vec{n}) = \sum \limits_{k < g(\vec{n})} f(\vec{n}, k)$
    \end{center}
    We have either $f(\vec{n}) \models \Gamma(\vec{n})$ or, by persistence, $B'(\vec{n}, k)$ is true for every $k < t(\vec{n})$.
    So $f \models \Gamma, \forall y B(y)$ and $f$ is elementary.
    \item Assume $\Gamma, \exists y A(y, \vec{x})$ is derivable, so $\Gamma, A(t, \vec{x})$ is derivable for some term $t$.
    By the IH, there is elementary $f_0$ such that for all $\vec{n}$ one has
    \begin{center}
      $f_0(\vec{n}) \models \Gamma(\vec{n}), A(t(\vec{n}), \vec{n})$
    \end{center}
    Then either $f_0(\vec{n}) \models \Gamma(\vec{n})$ or else $f_0(\vec{n})$ bounds true witnesses for all
    existential quantifiers in $A(t(\vec{n}), \vec{n})$. Choose an elementary function $g$ which is bounding for $t$.
    Define $f(\vec{n}) = f_0(\vec{n}) + g(\vec{n})$, then for all $\vec{n}$ either 
    $f(\vec{n}) \models \Gamma(\vec{n})$ or $f(\vec{n}) \models \exists y A(y, \vec{n})$.
    \item Assume $\Gamma$ comes about by the cut rule with $\Sigma_1$ formula 
    $C \eqcirc \exists \vec{z} B(\vec{z})$, so the premises are
    $\Gamma, \forall \vec{z} \neg B(\vec{z})$ and $\Gamma, \exists \vec{z} B(\vec{z})$.

    Without increasing the height of a proof, we can invert all universal quantifiers
    in the first premise. So we have $\neg B(\vec{z})$. $B$ is bounded, so the induction hypothesis
    can be applied to this formula to obtain an elementary function $f_0$ such that, 
    for all assignments $[\vec{x} := \vec{n}]$ and $[\vec{z} := \vec{m}]$
    \begin{center}
      $f_0(\vec{n}, \vec{m}) \models \Gamma(\vec{n}), \neg B(\vec{n}, \vec{m})$
    \end{center}
    Now we apply the induction hypothesis to the second premise of the cut rule, so we have an elementary function
    $f_1$ such that for all $\vec{n}$ either 
    $f_1(\vec{n}) \models \Gamma(\vec{n})$ or there are fixed witnesses $\vec{m} < f_1(\vec{n})$
    such that $B(\vec{n}, \vec{m})$ is true.

    Define $f$ the following way:
    \begin{center}
      $f(\vec{n}) = f_0(\vec{n}, f_1(\vec{n}), \dots, f_1(\vec{n}))$
    \end{center}
    Furthermore $f \models \Gamma$. For otherwise there would be a tuple $\vec{n}$ such that
    $\Gamma(\vec{n})$ is not true at $f(\vec{n})$, so, by persistence, 
    $\Gamma(\vec{n})$ is not true at $f_1(\vec{n})$.
    Thus $B(\vec{n}, \vec{m})$ is true for particular numbers $\vec{m} < f_1(\vec{n})$.
    But then $f_0(\vec{n}, \vec{m}) < f(\vec{n})$, so, by persistence, $\Gamma(\vec{n})$ cannot be true at 
    $f_0(\vec{n}, \vec{m})$. Thus $B(\vec{n}, \vec{m})$ is false, so we have a contradiction.
    \item Finally suppose $\Gamma(\vec{x}), B(\vec{x}, t)$ comes from the induction rule on a bounded formula $B$.
    The premises of the rule $\Gamma(\vec{x}), B(\vec{x}, 0)$ and $\Gamma(\vec{x}), \neg B(\vec{x}, y), B(\vec{x}, y + 1)$.

    Let us apply the induction hypothesis to each of the premises, and then we obtain
    increasing elementary functions $f_0$ and $f_1$ such that for all $\vec{n}$ and for all $k$

    \begin{center}
      $f_0(\vec{n}) \models \Gamma(\vec{n}), B(\vec{n}, 0)$

      $f_1(\vec{n}, k) \models \Gamma(\vec{n}), \neg B(\vec{n}, k), B(\vec{n}, k + 1)$
    \end{center}

    Now let
    \begin{center}
      $f(\vec{n}) = f_0(\vec{n}) + \sum \limits_{k < g(\vec{n})} f_1(\vec{n}, k)$
    \end{center}
    where $g$ is an increasing elementary function which is bounding for the term $t$.
    $f$ is elementary and increasing, and, by persistence for $f_0$ and $f_1$, we have either
    $f(\vec{n}) \models \Gamma(\vec{n})$ or else
    $B(\vec{n}, 0)$ and $B(\vec{n}, k) \to B(\vec{n}, k + 1)$ are true for all $k < t(\vec{n})$.
    In either case, we have $f \models \Gamma(\vec{x}), B(\vec{x}, t(\vec{x}))$.
  \end{enumerate}
\end{proof}

\begin{theorem}
  A number-theoretic function is elementary iff $f$ is provably $\Sigma_1$ in ${\bf I}\Delta_0(exp)$.
\end{theorem}

\begin{proof}
  The only if part is in Theorem~\ref{provablysigma1:1}, so we show the if part only.
  Assume $f$ is provably $\Sigma_1$ in ${\bf I}\Delta_0(exp)$. Then we have a formula
  \begin{center}
    $F(\vec{x}, y) = \exists z_1 \dots \exists z_k B(\vec{x}, y, z_1, \dots, z_k)$
  \end{center}
  which defines $f$ and such that
  \begin{center}
  ${\bf I}\Delta_0(exp) \models \exists y F(\vec{x}, y)$
  \end{center}
  By Lemma~\ref{truth:idelta0}, there exists an elementary function $g$ such that for every
  tuple of arguments $\vec{n}$ there are numbers $m_0, \dots, m_k$
  less that $g(n)$ satisfying the bounded formula $B(\vec{n}, m_0, m_1, \dots, m_k)$.
  Apply the elementary sequence coding:
  \begin{center}
    $h(\vec{n}) = \langle g(\vec{n}), g(\vec{n}), \dots, g(\vec{n})\rangle$
  \end{center}
  so that if $m = \langle m_0, m_1, \dots, m_k \rangle$
  where $m_i < g(\vec{n})$ for each $i \in n + 1$, so $m < h(\vec{n})$.

  As far as $f(\vec{n})$ is the unique $m_0$ for which there are $m_1, \dots, m_k$ satisfying
  $B(\vec{n}, m_0, \dots, m_k)$, we define $f$ as:
  \begin{center}
    $f(\vec{n}) = (\mu_{m < h(\vec{n})} B(\vec{n}, (m)_0, (m)_1, \dots, (m)_k))_0$.
  \end{center}

  $B$ is a bounded formula of ${\bf I}\Delta_0(exp)$, $B$ is elementarily 
  decidable. Moreover, elementary functions are closed under composition and bounded minimisation,
  so $f$ is elementary.
\end{proof}

\section{Primitive Recursion and ${\bf I}\Sigma_1$}

${\bf I}\Sigma_1$ is an arithmetical theory where the induction scheme is
restructed to $\Sigma_1$ formulas.

\begin{lemma}
  Every primitive recursion is provably recursive in ${\bf I}\Sigma_1$.
\end{lemma}

\begin{proof}
  We have to show represent each primitive recursive function $f$ with a $\Sigma_1$ formula 
  $F(\vec{x}, y) := \exists z C(\vec{x}, y, z)$ such that:
  \begin{enumerate}
    \item $f(\vec{n}) = m$ iff $\omega \models F(\vec{x}, y)$.
    \item ${\bf I}\Sigma_1 \vdash \exists y F(\vec{x}, y)$.
    \item ${\bf I}\Sigma_1 \vdash F(\vec{x}, y) \land F(\vec{x}, y') \to y = y'$.
  \end{enumerate}

  In each case $C(\vec{x}, y, z)$ will be a $\Delta_0(exp)$-formula
  constructed via sequence encoding in ${\bf I}\Delta_0(exp)$.
  Such a formula expresses that $z$ is a uniquely determined sequence number encoding the computation of
  $f(\vec{x}) = y$ and containing the output value $y$ as its final element, so $y = \pi_2(z)$.

  Condition 1 will hold by the definition of $C$. 
  Condition 3 will be satisfied by the uniqueness of $z$. We consider five definitional schemes by which $f$ could be
  introduced:
  \begin{enumerate}
    \item $f$ is the constant-zero function, that is, $f(x) = 0$, no matter what $x$ is.
    Then we take $C := y = 0 \land z = \langle 0 \rangle$. All the conditions are obviously satisfied.
    \item If $f$ is the successor function $f(x) = x + 1$, we let
    \begin{center}
      $C(x,y,z) := y = x + 1 \land z = \langle x + 1 \rangle$
    \end{center}
    All the conditions are obvious.
    \item Now assume $f$ is the projection function $f(x_0, \dots, x_n) = x_i$ for some $i \in n + 1$.
    We let
    \begin{center}
      $C(\vec{x},y,z) := y = x_i \land z = \langle x_i \rangle$
    \end{center}
    \item Now assume $f$ is defined by substitution from previously generated primitive recursive functions $f_0, f_1, f_2$:
    \begin{center}
      $f(\vec{x}) = f_0(f_1(\vec{x}), f_2(\vec{x}))$
    \end{center}

    By the induction hypothesis, assume thatb $f_0, f_1, f_2$ are provably recursive and we have 
    $\Delta_0(exp)$-formulas $C_0, C_1, C_2$ encoding their computations ($\operatorname{len}(z) = 4$).
    For the function $f$ define:
    \begin{center}
      $C(\vec{x}, y, z) := \bigwedge \limits_{i \in \{ 1, 2\}} C_i(\vec{x}, \pi_2((z)_i), (z)_i) \land 
      C_0(\pi_2((z)_1), \pi_2((z)_2), y, (z)_0) \land (z)_3 = y$.
    \end{center}

    Let us check the required conditions:
    \begin{enumerate}
      \item Condition 1 holds since $f(\vec{n}) = m$ iff there are numbers $m_1$ and $m_2$ such that
      $f_1(\vec{n}) = m_1$, $f_2(\vec{n}) = m_2$ and $f_0(m_1, m_2) = m$.
      These hold if and only if there are number $k_1, k_2, k_0$ such that 
      $C_1(\vec{n}, m_1, k_1)$, $C_2(\vec{n}, m_2, k_2)$ and $C_0(m_1, m_2, m, k_0)$ are all true.
      And these hold if and only if $C(\vec{n}, m, \langle k_0, k_1, k_2, m \rangle)$ is true.
      Thus $f(\vec{n}) = m $ iff and only if $F(\vec{n}, m) = \exists z C(\vec{n}, m, z)$ is true.
      \item Condition 2 holds since from $C_1(\vec{x}, y_1, z_1)$, $C_2(\vec{x}, y_2, z_2)$
      and $C(y_1, y_2, y, z_0)$ we can derive 
      $C(\vec{x}, y, \langle z_0, z_1, z_2, y \rangle)$ in ${\bf I}\Delta_0$.
      So provided $\exists y \exists z C_1(\vec{x}, y, z)$, $\exists y \exists z C_2(\vec{x}, y, z)$ and
      $\forall y_1 \forall y_2 \exists y \exists z C(y_1, y_2, y, z)$, we can prove $\exists y F(\vec{x}, y) := 
      C(\vec{x}, y, z)$.
      \item Condition 3 is self-evident.
    \end{enumerate}
    \item Now assume that $f$ is defined from $f_1$ and $f_2$ by primitive recursion:
    \begin{center}
      $f(\vec{v}, 0) = f_0(\vec{v})$

      $f(\vec{v}, x + 1) = f_1(\vec{v}, x, f(\vec{v}, x))$
    \end{center}
    By the induction hypothesis $f_0$ and $f_1$ are provably recursive and they have associated $\Delta_0$-formulas
    $C_0$ and $C_1$. Define
    \begin{center}
    $\begin{array}{lll}
      & C(\vec{v}, x, y, z) := C_0(\vec{v}, \pi_2((z)_0), (z)_0) \land & \\
      & \:\:\:\: \forall i < x \:\: (C_i (\vec{v}, i, \pi_2((z)_i), \pi_2((z)_{i + 1}))) \land & \\
      & \:\:\:\: (z)_{x + 1} = y \land \pi_2((z)_x) = y &
    \end{array}$
  \end{center}

  Let us check that all the conditions are satisfied:
  \begin{enumerate}
    \item Condition 1 holds since $f(\vec{l}, n) = m$ if and only if there is a sequence number
    $k = \langle k_0, \dots, k_n, m \rangle$ such that $k_0$ encodes the computation of 
    $f(\vec{l}, 0)$ with the value $\pi_2(k_0)$, and for each $i < n$, 
    $k_{i + 1}$ codes the computation of $f(\vec{l}, i + 1) = f_1(\vec{l}, i, \pi_2(k_i))$
    with values $\pi_2(k_{i + 1})$ and $\pi_2(k_n) = m$.
    This is equivalent to $\models F(\vec{l}, n, m) \leftrightarrow \exists z C(\vec{l}, n,m, z)$.
    \item To show Condition 2 we have to prove the following in ${\bf I}\Delta_0$
    \begin{center}
      $C_0(\vec{v}, y, z) \to C(\vec{v}, 0, y, \langle z, y \rangle)$
    \end{center}
    and
    \begin{center}
      $C(\vec{v}, x, y, z) \land C_1(\vec{v}, x, y,y',z') \to C(\vec{v}, x + 1, y', t)$
    \end{center}
    for a suitable term $t$ which removes the end component $y$ of $z$ and replaces it by $z'$, 
    and then adds the final component $y'$. More specifically
    \begin{center}
      $t = \pi(\pi(\pi_1(z), z'), y')$
    \end{center}
    Hence from $\exists y \exists z C_0(\vec{v},y,z)$ we obtain 
    $\exists y \exists z C(\vec{v}, 0, y, z)$, and from $\forall y \exists y' \exists z' C_1(\vec{v}, x, y, y', z')$ one can derive
    \begin{center}
      $\exists y \exists z C(\vec{v}, x,y,z) \to \exists y \exists z C(\vec{v}, x + 1, y, z)$
    \end{center}
    We have assumed that $f_0$ and $f_1$ are primitive recursive, we can prove $\exists y F(\vec{v}, 0, y)$
    and $\exists y F(\vec{v}, x, y) \to \exists y F(\vec{v}, x + 1, y)$.
    Then we derive $\exists y F(\vec{v}, x, y)$ by using $\Sigma_1$-induction.
    \item To show Condition 3 assume $C(\vec{v}, x, y, z)$ and $C(\vec{v}, x, y',z')$, where
    $z$ and $z'$ are sequence numbers of the same length $x + 2$.
    Furthermore we have $C_0(\vec{v}, \pi_2((z)_0), (z)_0)$
    and $C_0(\vec{v}, \pi_2((z')_0), (z')_0)$, so we have $(z)_0 = (z')_0$.

    Similarly we have $\forall i < x \:\: C_1(\vec{v}, i, \pi_2((z)_i), \pi_2((z)_{i + 1}), (z)_{i + 1})$
    and the same formula where $z$ is replaced by $z'$.
    So if $(z)_i = (z')_i$, and one can deduce $(z)_{i + 1} = (z')_{i + 1}$ using the uniquness assumption
    for $C_1$. By $\Delta_0(exp)$-induction we obtain $\forall i \leq x \:\: ((z)_i = (z')_i)$.

    The final conjuncts in $C$ give $(z)_{x + 1} = \pi_2((z)_x) = y$ and the same formulas where $z$ is replaced by $z'$ 
    and where $y$ is replaced by $y'$. But since $(z)_x = (z')_x$ we have $y = y'$, since all the components are equal,
    $z = z'$. Thus we have $F(\vec{v}, x, y) \land F(\vec{v}, x, y') \to y = y'$.
  \end{enumerate}
  \end{enumerate}
\end{proof}

\subsection{${\bf I}\Sigma_1$ provable functions are primitive recursive}

\begin{definition}
  A closed $\Sigma_1$-formula $\exists \vec{z} B(z)$ with $B \in \Delta_0(exp)$ is said to be
  ``true at $m$'' (denoted as $m \models \exists \vec{z} B(z)$) if there are numbers
  $\vec{m} = (m_1, \dots, m_l)$ such that all $m_i < m$ for $i \in \{1, \dots, l\}$
  such that $B(\vec{m})$ is true in the standard model.
  
  A finite set of formulas $\Gamma$ of closed $\Sigma_1$-formulas is ``true at $m$'' 
  (denoted as $m \models \Gamma$) if at least one of them is true at $m$.

  If $\Gamma(x_1, \dots, x_k)$ is a finite set of $\Sigma_1$-formulas all of whose
  free variables occur amongst $x_1, \dots, x_k$ and if $f : \mathbb{N}^k \to \mathbb{N}$, then we write 
  $f \models \Gamma$ if for each assignments $\vec{n} = (n_1, \dots, n_k)$ to the variables  $x_1, \dots, x_k$
  we have $f(\vec{n}) \models \Gamma(\vec{n})$.
\end{definition}

Note that we have the persistence property for $\models$ 
which completely repeats persistence for ${\bf I}\Delta_0(exp)$.

We shall be using a Tait-style formalisation of ${\bf I}\Sigma_0$ where the induction rule

\begin{prooftree}
  \AxiomC{$\Gamma, A(0)$}
  \AxiomC{$\Gamma, \neg A(y), A(y + 1)$}
  \BinaryInfC{$\Gamma, A(t)$}
\end{prooftree}

where $y$ is not free in $\Gamma$, $t$ is any term and $A$ is any $\Sigma_1$-formula.

\begin{lemma} ($\Sigma_1$-induction)
  Let $\Gamma(\vec{x})$ be a finite set of $\Sigma_1$-formulas such that
  \begin{center}
    ${\bf I}\Sigma_1 \vdash \bigvee \Gamma(\vec{x})$
  \end{center}
  then there is a primitive recursive function $f$ such that $f \models \Gamma$ and $f$ is strictly increasing
  on its variables.
\end{lemma}

\begin{proof}
  We note that if $\Gamma$ is provable in this formalisation, then
it has a proof in which all the non-atomic cut formulas are induction $\Sigma_1$-formulas.
If $\Gamma$ is classically derivable from non-logical axioms $A_1, \dots, A_s$,
then there is a cut-free proof (\`{a} la Tait) of $\neg A_1, \Delta, \Gamma$ where $\Delta = A_2, \dots, A_s$.
Then if $A_1$ is an induction axiom on a formula $F$, then we have have a cut-free proof of
\begin{center}
  $F(0) \land \forall y (\neg F(y) \lor F(y + 1)) \land \neg F(t), \Delta, \Gamma$
\end{center}
and thus, by inversion, we have cut-free proofs of $F(0), \Delta, \Gamma$, 
$\neg F(y), F(y + 1), \Delta, \Gamma$ and $\neg F(t), \Delta, \Gamma$.

So we obtain $F(t), \Delta, \Gamma$ by the induction rule and then we obtain $\Delta, \Gamma$ by cutting $F(t)$.
One can detach $\neg A_2, \dots, \neg A_s$, so we finally have a proof of $\Gamma$ which uses cuts only
on $\Sigma_1$-induction formulas or on atoms arising from non-logical axioms. Such proofs are said to be ``free-cut'' free.

Let us choose such a proof for $\Gamma(\vec{x})$ and show by induction on the height of a proof that there exists
a primitive recursive function satisfying $f \models \Gamma$.

\begin{enumerate}
  \item Let $\Gamma(\vec{x})$ be an axiom, the for all $\vec{n}$ $\Gamma(\vec{n})$ contains a true atom.
  Choose $f(\vec{n}) = n_1 + \dots + n_k$, and $f$ is clearly primitive recursive, strictly incrasing and $f \models \Gamma$.
  \item Assume we have
  \begin{prooftree}
    \AxiomC{$\Gamma, B_0, B_1$}
    \RightLabel{$\lor$}
    \UnaryInfC{$\Gamma, B_0 \lor B_1$}
  \end{prooftree}
  Then both $B_0$ and $B_1$ are both $\Delta_0(exp)$-formulas, so any function $f$ satisfying 
  $f \models \Gamma, B_0, B_1$ also satisfies $\Gamma, B_0 \lor B_1$.
  \item Assume we have
  \begin{prooftree}
    \AxiomC{$\Gamma, B_0$}
    \AxiomC{$\Gamma, B_1$}
    \RightLabel{$\land$}
    \BinaryInfC{$\Gamma, B_0 \land B_1$}
  \end{prooftree}
  By the induction hypothesis we have $f_i(\vec{n}) \models \Gamma(\vec{n}), B_i(\vec{n})$ where $i \in \{0,1\}$ for all $\vec{n}$.
  By the persistence property, $\lambda \vec{n}. f_0(\vec{n}) + f_1(\vec{n}) \models \Gamma, B_0 \land B_1$.
  \item Assume we have
  \begin{prooftree}
    \AxiomC{$\Gamma, B(y)$}
    \RightLabel{$\forall$}
    \UnaryInfC{$\Gamma, \forall y B(y)$}
  \end{prooftree}
  where $y$ is not free in $\Gamma$. As far as all formulas are $\Sigma_1$, $\forall y B(y)$ 
  must be ${\bf I}\Delta_0(exp)$, so $B(y) \eqcirc \neg(y < t) \lor B'(y)$ for some elemetary or primitive recursive term $t$.
  Assume we have $f_0 \models \Gamma, \neg(y < t) \lor B'(y)$ for some increasing primitive recursive function $f_0$.
  Then, for any assignments $\vec{x} \mapsto \vec{n}$ and $y \mapsto k$, we have
  \begin{center}
    $f_0(\vec{n}, k) \models \Gamma(\vec{n}), \neg (k < t(\vec{n})), B'(\vec{n}, k)$.
  \end{center}
  We let
  \begin{center}
    $f(\vec{n}) = \sum \limits_{k < g(\vec{n})} f_0(\vec{n}, k)$
  \end{center}
  for some function $g$, which is increasing primitive recursive bounding the values of term $t$.
  So we have either $f(\vec{n}) \models \Gamma$ or $B'(\vec{n}, k)$ is true for every $k < t(\vec{n})$.
  Thus $f \models \Gamma, \forall y B(y)$ as required.
  \item Suppose we have
  \begin{prooftree}
    \AxiomC{$\Gamma, A(t)$}
    \RightLabel{$\exists$}
    \UnaryInfC{$\Gamma, \exists y A(y)$}
  \end{prooftree}
  where $A$ is a $\Sigma_1$-formula. By the induction hypothesis we have a function $f_0$ such that for all $\vec{n}$
  \begin{center}
    $f_0(\vec{n}) \models \Gamma(\vec{n}), A(t(\vec{n}), \vec{n})$
  \end{center}
  Then either $f_0(\vec{n}) \models \Gamma(\vec{n})$ or otherwise $f_0(\vec{n})$ 
  bounds true witnesses for all the existential quantifiers already in $A(t(\vec{n}, \vec{n}))$.
  Choose an elementary bounding function $g$ for the term $t$ and define 
  $f(\vec{n}) = f_0(\vec{n}) + g(\vec{n})$, so we have either 
  $f(\vec{n}) \models \Gamma(\vec{n})$ or $f(\vec{n}) \models \exists y A(y, \vec{n})$ for all $\vec{n}$.
  \item Assume we have
  \begin{prooftree}
    \AxiomC{$\Gamma, \forall \vec{z} \neg B(\vec{z})$}
    \AxiomC{$\Gamma, \exists \vec{z} B(\vec{z})$}
    \RightLabel{{\bf cut}}
    \BinaryInfC{$\Gamma$}
  \end{prooftree}
  where $\exists \vec{z} B(\vec{z})$ is a cut $\Sigma_1$-formula.
  
  Note that we have
  \begin{prooftree}
    \AxiomC{$\Gamma, \neg B(\vec{z})$}
    \RightLabel{$\forall$}
    \UnaryInfC{$\Gamma, \forall \vec{z} \neg B(\vec{z})$}
  \end{prooftree}
  Note $B$ is a $\Delta_0(\exp)$-formula, so let us apply the induction hypothesis to obtain a
  primitive recursive function $f_0$ such that for each assignments $\vec{x} \mapsto \vec{n}$ and $\vec{z} \mapsto \vec{m}$
  \begin{center}
    $f_0(\vec{n}, \vec{m}) \models \Gamma(\vec{n}), \neg B(\vec{n}, \vec{m})$.
  \end{center}
  We apply the induction hypothesis to the second premise to obtain a primitive recursive function $f_1$ such that
  for all $\vec{n}$ either $f_1(\vec{n}) \models \Gamma(\vec{n})$ or otherwise there are fixed witnesses 
  $\vec{m} < f_1(\vec{n})$ s.t. $B(\vec{n}, \vec{m})$ is true.
  Let us define $f$ by substitution:
  \begin{center}
    $f(\vec{n}) = f_0(\vec{n}, f_1(\vec{n}), \dots, f_1(\vec{n}))$
  \end{center}
  where $f$ is primitive recursive, greater or equal that $f_1$ (pointwise) and strictly increasing.
  Furthermore $f \models \Gamma$.
  
  For otherwise, let us suppose there exists a tuple $\vec{n}$ such that $\Gamma(\vec{n})$ is not true
  $f(\vec{n})$ and, thus, by persistence at $f_1(\vec{n})$. So $B(\vec{n}, \vec{m})$ is true for
  some $\vec{m} < f_1(\vec{n})$. Thus $f_0(\vec{n}, \vec{m}) < f(\vec{n})$, and then, by persistence, $\Gamma(\vec{n})$
  cannot be true at $f_0(\vec{n}, \vec{m})$. Then $B(\vec{n}, \vec{m})$, so we have a contradiction.
  \item Suppose we have
  \begin{prooftree}
    \AxiomC{$\Gamma(\vec{x}), A(\vec{x}, 0)$}
    \AxiomC{$\Gamma, \neg A(\vec{x}, y), A(\vec{x}, y + 1)$}
    \BinaryInfC{$\Gamma, A(\vec{x}, t)$}
  \end{prooftree}
  where $A(\vec{x}, y)$ is an induction $\Sigma_1$-formula of the form $\exists \vec{z} B(\vec{x}, y, \vec{z})$.
  Let us invert universal quantifiers in $\neg A(\vec{x}, y)$, the second premise of the rule becomes
   \begin{center}
     $\Gamma(\vec{x}), \neg B(\vec{x}, y, \vec{z}), A(\vec{x}, y + 1)$
   \end{center}
  which is now a set $\Sigma_1$-formulas. We can apply the induction hypothesis to each of the premises to
  have primitive recursive function $f_0$ and $f_1$ such that for each $\vec{n}$, $k$ and $\vec{m}$
  \begin{center}
    $f_0(\vec{n}) \models \Gamma(\vec{n}), A(\vec{n}, 0)$

    $f_1(\vec{n}, k, \vec{m}) \models \Gamma(\vec{n}), \neg B(\vec{n}, k, \vec{m}), A(\vec{n}, k + 1)$
  \end{center}
  Define $f$ by primitive recursion from $f_0$ and $f_1$ the following way
  \begin{center}
    $f(\vec{n}, 0) = f_0(\vec{n})$

    $f(\vec{n}, k + 1) = f_1(\vec{n}, k, f(\vec{n}, k), \dots, f(\vec{n}, k))$
  \end{center}

  Then for all $\vec{n}$ and for all $\vec{k}$ one has $f(\vec{n}, k) \models \Gamma(\vec{n}), A(\vec{n}, k)$ which is shown
  by induction on $k$.
  The base case holds by the definition of $f_0(\vec{n})$. For the induction step assume that 
  $f(\vec{n}, k) \models \Gamma(\vec{n}), A(\vec{n}, k)$. If $\Gamma(\vec{n})$ is not true at 
  $f(\vec{n}, k + 1)$. By persistence it is not true at $f(\vec{n}, k)$ and thus 
  $f(\vec{n}, k) \models A(\vec{n}, k)$.
  Therefore there are numbers $\vec{m} < f(\vec{n}, k)$ such that $B(\vec{n}, k, \vec{m})$ is true.
  Thus $f_1(\vec{n}, k, \vec{m}) \models \Gamma(\vec{n}), A(\vec{n}, k + 1)$ and since 
  $f_1(\vec{n}, k, \vec{m}) \leq f(\vec{n}, k + 1)$ we have, by persistence, $f(\vec{n}, k + 1) \models \Gamma(\vec{n}), A(\vec{n}, k + 1)$
  as required.

  So we substitute for the final argument $k$ in $f$ an elementary (or primitive recursive) function $g$
  which bounds the values of $t$, so that $f'(\vec{n}) = f(\vec{n}, g(\vec{n}))$, and thus
  we have $f(\vec{n}, t(\vec{n})) \models \Gamma(\vec{n}), A(\vec{n}, t(\vec{n}))$ for all $\vec{n}$ and thus, by persistence, $f' \models \Gamma(\vec{x}), A(\vec{x}, t)$.
\end{enumerate}
\end{proof}

\section{$\epsilon_0$ and Peano Arithmetic}

\section{${\bf RCA}_0$}

\section{${\bf WKL}_0$}

\section{${\bf ACA}_0$}

\section{${\bf ATR}$}

\section{${\bf \Pi_1^1}$-comprehension}

\section{Kripke-Platek Set Theory}


\bibliographystyle{alpha}
\bibliography{Text}

\end{document}